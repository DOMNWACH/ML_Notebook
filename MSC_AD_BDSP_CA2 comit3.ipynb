{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "source": [
    "<h2 align=\"center\" style=\"background-color:#2D3436;color:white;border-radius:8px;padding:15px\">Forecasting Stock Prices using Sentiment Analysis and Time Series Models: An Advanced Data Analytics Approach</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Table of Contents**\n",
    "\n",
    "- [Introduction](#Introduction)\n",
    "   - Assessment Overview\n",
    "   - Objectives\n",
    "   - Data Source and Storage\n",
    "- [Install and Import Required Libraries](#Install-and-Import-Required-Libraries)\n",
    "- [Load Dataset](#Load-Dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-28T08:23:52.241021Z",
     "iopub.status.busy": "2025-02-28T08:23:52.240719Z",
     "iopub.status.idle": "2025-02-28T08:23:52.247331Z",
     "shell.execute_reply": "2025-02-28T08:23:52.246134Z",
     "shell.execute_reply.started": "2025-02-28T08:23:52.240997Z"
    }
   },
   "source": [
    "<h3 style=\"background-color:#2D3436;color:white;border-radius:8px;padding:15px\">Introduction</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assessment Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-28T08:26:12.008598Z",
     "iopub.status.busy": "2025-02-28T08:26:12.008322Z",
     "iopub.status.idle": "2025-02-28T08:26:12.011797Z",
     "shell.execute_reply": "2025-02-28T08:26:12.010942Z",
     "shell.execute_reply.started": "2025-02-28T08:26:12.008574Z"
    }
   },
   "source": [
    "### Objectives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Source and Storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 style=\"background-color:#2D3436;color:white;border-radius:8px;padding:15px\">Install and Import Required Libraries</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-21T10:21:08.080390Z",
     "iopub.status.busy": "2025-04-21T10:21:08.079989Z",
     "iopub.status.idle": "2025-04-21T10:21:11.930077Z",
     "shell.execute_reply": "2025-04-21T10:21:11.928745Z",
     "shell.execute_reply.started": "2025-04-21T10:21:08.080359Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!pip install -q pyspark pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-21T10:21:11.932766Z",
     "iopub.status.busy": "2025-04-21T10:21:11.932416Z",
     "iopub.status.idle": "2025-04-21T10:21:13.377485Z",
     "shell.execute_reply": "2025-04-21T10:21:13.376294Z",
     "shell.execute_reply.started": "2025-04-21T10:21:11.932728Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "import sqlite3\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, count, when, lit, to_date, avg, stddev, desc, first\n",
    "from pyspark.sql.types import StructType, StructField, StringType, DoubleType, LongType\n",
    "from pyspark.sql.window import Window\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 style=\"background-color:#2D3436;color:white;border-radius:8px;padding:15px\">Load Dataset</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-21T08:52:42.600571Z",
     "iopub.status.busy": "2025-04-21T08:52:42.600276Z",
     "iopub.status.idle": "2025-04-21T08:52:42.605321Z",
     "shell.execute_reply": "2025-04-21T08:52:42.604154Z",
     "shell.execute_reply.started": "2025-04-21T08:52:42.600543Z"
    }
   },
   "source": [
    "#### **Initialize Spark Session and Define Data Paths**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-21T10:21:13.379523Z",
     "iopub.status.busy": "2025-04-21T10:21:13.378863Z",
     "iopub.status.idle": "2025-04-21T10:21:18.579067Z",
     "shell.execute_reply": "2025-04-21T10:21:18.577708Z",
     "shell.execute_reply.started": "2025-04-21T10:21:13.379486Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/04/21 10:21:16 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Stock Tweet Analysis\") \\\n",
    "    .config(\"spark.memory.offHeap.enabled\", \"true\") \\\n",
    "    .config(\"spark.memory.offHeap.size\", \"10g\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-21T10:21:18.582094Z",
     "iopub.status.busy": "2025-04-21T10:21:18.581719Z",
     "iopub.status.idle": "2025-04-21T10:21:18.589853Z",
     "shell.execute_reply": "2025-04-21T10:21:18.588745Z",
     "shell.execute_reply.started": "2025-04-21T10:21:18.582064Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "spark.sparkContext.setLogLevel(\"ERROR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-21T10:21:18.591500Z",
     "iopub.status.busy": "2025-04-21T10:21:18.591145Z",
     "iopub.status.idle": "2025-04-21T10:21:18.613497Z",
     "shell.execute_reply": "2025-04-21T10:21:18.612685Z",
     "shell.execute_reply.started": "2025-04-21T10:21:18.591474Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "tweet_data_path = \"/kaggle/input/stock-tweet-and-price/stock-tweet-and-price/stocktweet/stocktweet.csv\"\n",
    "stock_price_folder = \"/kaggle/input/stock-tweet-and-price/stock-tweet-and-price/stockprice\"\n",
    "db_path = \"stock_analysis.db\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Define Data Schemas**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-21T10:21:18.615167Z",
     "iopub.status.busy": "2025-04-21T10:21:18.614632Z",
     "iopub.status.idle": "2025-04-21T10:21:18.635955Z",
     "shell.execute_reply": "2025-04-21T10:21:18.634093Z",
     "shell.execute_reply.started": "2025-04-21T10:21:18.615136Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Define the companies to analyze\n",
    "companies = ['AAPL', 'AMZN', 'MSFT', 'TSLA', 'GOOGL', 'FB']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-21T10:21:18.638158Z",
     "iopub.status.busy": "2025-04-21T10:21:18.637753Z",
     "iopub.status.idle": "2025-04-21T10:21:18.658930Z",
     "shell.execute_reply": "2025-04-21T10:21:18.657130Z",
     "shell.execute_reply.started": "2025-04-21T10:21:18.638125Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Define schema for tweet data\n",
    "tweet_schema = StructType([\n",
    "    StructField(\"id\", StringType(), True),\n",
    "    StructField(\"date\", StringType(), True),\n",
    "    StructField(\"ticker\", StringType(), True),\n",
    "    StructField(\"tweet\", StringType(), True)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-21T10:21:18.661224Z",
     "iopub.status.busy": "2025-04-21T10:21:18.660829Z",
     "iopub.status.idle": "2025-04-21T10:21:18.683564Z",
     "shell.execute_reply": "2025-04-21T10:21:18.682389Z",
     "shell.execute_reply.started": "2025-04-21T10:21:18.661178Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Define schema for stock price data\n",
    "stock_schema = StructType([\n",
    "    StructField(\"Date\", StringType(), True),\n",
    "    StructField(\"Open\", DoubleType(), True),\n",
    "    StructField(\"High\", DoubleType(), True),\n",
    "    StructField(\"Low\", DoubleType(), True),\n",
    "    StructField(\"Close\", DoubleType(), True),\n",
    "    StructField(\"Adj Close\", DoubleType(), True),\n",
    "    StructField(\"Volume\", LongType(), True)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Define Helper Functions for Loading Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-21T10:21:18.685162Z",
     "iopub.status.busy": "2025-04-21T10:21:18.684802Z",
     "iopub.status.idle": "2025-04-21T10:21:18.705345Z",
     "shell.execute_reply": "2025-04-21T10:21:18.704080Z",
     "shell.execute_reply.started": "2025-04-21T10:21:18.685127Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def load_tweet_data():\n",
    "    df = spark.read.csv(tweet_data_path, header=True, schema=tweet_schema)\n",
    "    # Convert date string to standard format\n",
    "    df = df.withColumn(\"date\", to_date(col(\"date\"), \"MM/dd/yyyy\"))\n",
    "    # Filter tweets for selected companies\n",
    "    df = df.filter(col(\"ticker\").isin(companies))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-21T10:21:18.711052Z",
     "iopub.status.busy": "2025-04-21T10:21:18.709918Z",
     "iopub.status.idle": "2025-04-21T10:21:18.728703Z",
     "shell.execute_reply": "2025-04-21T10:21:18.727631Z",
     "shell.execute_reply.started": "2025-04-21T10:21:18.710999Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def load_stock_data(ticker):\n",
    "    file_path = os.path.join(stock_price_folder, f\"{ticker}.csv\")\n",
    "    df = spark.read.csv(file_path, header=True, schema=stock_schema)\n",
    "    # Convert date string to standard format\n",
    "    df = df.withColumn(\"Date\", to_date(col(\"Date\"), \"yyyy-MM-dd\"))\n",
    "    # Add ticker column\n",
    "    df = df.withColumn(\"ticker\", lit(ticker))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-21T09:00:34.661605Z",
     "iopub.status.busy": "2025-04-21T09:00:34.661221Z",
     "iopub.status.idle": "2025-04-21T09:00:34.666682Z",
     "shell.execute_reply": "2025-04-21T09:00:34.665667Z",
     "shell.execute_reply.started": "2025-04-21T09:00:34.661560Z"
    }
   },
   "source": [
    "#### **Load Datasets using Helper Functions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-21T10:21:18.730357Z",
     "iopub.status.busy": "2025-04-21T10:21:18.730009Z",
     "iopub.status.idle": "2025-04-21T10:21:22.083258Z",
     "shell.execute_reply": "2025-04-21T10:21:22.080963Z",
     "shell.execute_reply.started": "2025-04-21T10:21:18.730331Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading tweet data...\n",
      "Tweet data loaded\n"
     ]
    }
   ],
   "source": [
    "print(\"Loading tweet data...\")\n",
    "tweets_df = load_tweet_data()\n",
    "print(\"Tweet data loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-21T10:21:22.084750Z",
     "iopub.status.busy": "2025-04-21T10:21:22.084352Z",
     "iopub.status.idle": "2025-04-21T10:21:22.710721Z",
     "shell.execute_reply": "2025-04-21T10:21:22.709560Z",
     "shell.execute_reply.started": "2025-04-21T10:21:22.084721Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading stock price data...\n",
      "Stock price data loaded\n"
     ]
    }
   ],
   "source": [
    "print(\"Loading stock price data...\")\n",
    "stock_dfs = {}\n",
    "for company in companies:\n",
    "    stock_dfs[company] = load_stock_data(company)\n",
    "print(\"Stock price data loaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 style=\"background-color:#2D3436;color:white;border-radius:8px;padding:15px\">Data Exploration</h3>"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 7150469,
     "sourceId": 11417157,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31012,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
