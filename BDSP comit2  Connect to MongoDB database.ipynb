{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "923bcb38",
   "metadata": {},
   "source": [
    "<h1 align=\"center\" style=\"background-color:#2c3e54;color:#ecf0f1;border-radius: 8px; padding:15px\">MSc in Data Analytics: Big Data Storage and Processing</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d805034",
   "metadata": {},
   "source": [
    "### Table of Contents\n",
    "\n",
    "- [Introduction](#Introduction)\n",
    "    - [Assessment Overview](#Assessment-Overview)\n",
    "    - [Project Summary](#Project-Summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2e0502b",
   "metadata": {},
   "source": [
    "<h2 style=\"background-color:#2c3e54;color:#ecf0f1;border-radius: 8px; padding:15px\">Introduction</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fcb5eed",
   "metadata": {},
   "source": [
    "### **Assessment Overview**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef855670",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "db0a1465",
   "metadata": {},
   "source": [
    "### Project Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "184e2659",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bce8a253",
   "metadata": {},
   "source": [
    "<h2 style=\"background-color:#2c3e54;color:#ecf0f1;border-radius: 8px; padding:15px\">Install and Import Required Libraries</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "302fe9f3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-14T18:39:32.666380Z",
     "iopub.status.busy": "2025-07-14T18:39:32.665981Z",
     "iopub.status.idle": "2025-07-14T18:39:32.672666Z",
     "shell.execute_reply": "2025-07-14T18:39:32.671542Z",
     "shell.execute_reply.started": "2025-07-14T18:39:32.666350Z"
    }
   },
   "outputs": [],
   "source": [
    "# !pip install -q pyspark pymongo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "709169ef",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-14T18:39:32.707810Z",
     "iopub.status.busy": "2025-07-14T18:39:32.707395Z",
     "iopub.status.idle": "2025-07-14T18:39:33.477834Z",
     "shell.execute_reply": "2025-07-14T18:39:33.476330Z",
     "shell.execute_reply.started": "2025-07-14T18:39:32.707774Z"
    }
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "from datetime import datetime\n",
    "import logging\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import pymongo\n",
    "from pymongo import MongoClient\n",
    "\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import lit\n",
    "\n",
    "from kaggle_secrets import UserSecretsClient\n",
    "\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "56b8b63c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-14T18:39:33.481458Z",
     "iopub.status.busy": "2025-07-14T18:39:33.480131Z",
     "iopub.status.idle": "2025-07-14T18:39:33.487510Z",
     "shell.execute_reply": "2025-07-14T18:39:33.486279Z",
     "shell.execute_reply.started": "2025-07-14T18:39:33.481407Z"
    }
   },
   "outputs": [],
   "source": [
    "# Configure logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s — %(levelname)s %(message)s', force=True)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Disable warnings\n",
    "warnings.filterwarnings(action='ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f1b1730",
   "metadata": {},
   "source": [
    "<h2 style=\"background-color:#2c3e54;color:#ecf0f1;border-radius: 8px; padding:15px\">Define Data Paths</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "264f9050",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-14T18:39:33.489524Z",
     "iopub.status.busy": "2025-07-14T18:39:33.489031Z",
     "iopub.status.idle": "2025-07-14T18:39:33.511870Z",
     "shell.execute_reply": "2025-07-14T18:39:33.510572Z",
     "shell.execute_reply.started": "2025-07-14T18:39:33.489471Z"
    }
   },
   "outputs": [],
   "source": [
    "STOCKPRICE_FOLDER = \"/kaggle/input/stock-tweet-and-price/stock-tweet-and-price/stockprice\"\n",
    "STOCKTWEET_CSV = \"/kaggle/input/stock-tweet-and-price/stock-tweet-and-price/stocktweet/stocktweet.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c158e95c",
   "metadata": {},
   "source": [
    "<h2 style=\"background-color:#2c3e54;color:#ecf0f1;border-radius: 8px; padding:15px\">Set MongoDB Connection</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a8393259",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-14T18:39:33.514598Z",
     "iopub.status.busy": "2025-07-14T18:39:33.514017Z",
     "iopub.status.idle": "2025-07-14T18:39:33.710304Z",
     "shell.execute_reply": "2025-07-14T18:39:33.708598Z",
     "shell.execute_reply.started": "2025-07-14T18:39:33.514560Z"
    }
   },
   "outputs": [],
   "source": [
    "user_secrets = UserSecretsClient()\n",
    "mongodb_uri = user_secrets.get_secret(\"mongodb-atlas-uri\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9e8afdbc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-14T18:39:33.712587Z",
     "iopub.status.busy": "2025-07-14T18:39:33.712223Z",
     "iopub.status.idle": "2025-07-14T18:39:34.454531Z",
     "shell.execute_reply": "2025-07-14T18:39:34.453590Z",
     "shell.execute_reply.started": "2025-07-14T18:39:33.712558Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-14 18:39:34,449 — INFO Connected to MongoDB database: stock_analytics\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MongoDB version: 8.0.11\n"
     ]
    }
   ],
   "source": [
    "def create_mongodb_connection(uri, db_name='stock_analytics'):\n",
    "    \"\"\"\n",
    "    Connect to MongoDB and return database instance\n",
    "    \n",
    "    Args:\n",
    "        uri (str): Database URI\n",
    "        db_name (str): Database name\n",
    "    \n",
    "    Returns:\n",
    "        pymongo.database.Database: MongoDB database instance\n",
    "    \"\"\"\n",
    "    try:\n",
    "        client = MongoClient(uri)\n",
    "        db = client[db_name]\n",
    "        print(\"MongoDB version:\", client.server_info()[\"version\"])\n",
    "        logger.info(f\"Connected to MongoDB database: {db_name}\")\n",
    "        return db\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Failed to connect to MongoDB: {e}\")\n",
    "        raise\n",
    "\n",
    "db = create_mongodb_connection(mongodb_uri, 'stock_analytics')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bff3ec8",
   "metadata": {},
   "source": [
    "### MongoDB Selection Rationale\n",
    "\n",
    "**Why MongoDB was chosen over other NoSQL options:**\n",
    "\n",
    "\n",
    "* **Document-oriented structure**\n",
    "\n",
    "  * MongoDB’s JSON-like document model naturally accommodates the semi-structured `stocktweet.csv` data (e.g., tweet text, ticker, and timestamp).\n",
    "  * No need for complex schema definitions or rigid table structures.\n",
    "\n",
    "* **Ease of use and developer-friendliness**\n",
    "  * It is easy to get started with MongoDB. The installation process is easy as well as connecting to the database\n",
    "  * MongoDB’s query language (MQL) is intuitive and similar to JSON syntax, which makes it easy to write.\n",
    "  * Rich developer tools such as MongoDB Compass which helps me visualize the database. E.g when I have created a collection, inserted a data, and so on.\n",
    "  * Extensive support for multiple programming languages (e.g., Python, Java, Scala).\n",
    "\n",
    "* **Seamless integration with Apache Spark**\n",
    "\n",
    "  * The `mongo-spark-connector` enables direct read/write access between MongoDB and Spark DataFrames.\n",
    "  * Simplifies data ingestion, distributed transformation, and analytics within the Spark environment.\n",
    "\n",
    "* **Efficient for read-heavy analytical workloads**\n",
    "\n",
    "  * MongoDB supports secondary indexing and text search—ideal for querying tweets by ticker symbol or date.\n",
    "  * Aggregation pipelines allow for efficient summarization and filtering of large datasets.\n",
    "\n",
    "* **Cloud accessibility and scalability**\n",
    "\n",
    "  * MongoDB Atlas provides a fully managed cloud database service that allows me to connect securely from anywhere.\n",
    "  * I can easily deploy and scale MongoDB clusters in the cloud and integrate them with my local Spark environment.\n",
    "  * Atlas ensures high availability, backup, and monitoring, which is ideal for handling large-scale, real-time tweet and stock data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6ac1741",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 7150469,
     "sourceId": 11417157,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31089,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
